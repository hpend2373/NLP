{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IKEA MEPNet Adapter Training\n",
    "\n",
    "This notebook trains the MEPNet model adapted for IKEA furniture assembly instructions.\n",
    "\n",
    "**Requirements:**\n",
    "- GPU runtime (T4 or better recommended)\n",
    "- ~15GB disk space for dataset\n",
    "- ~8GB GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/hpend2373/NLP.git\n",
    "%cd NLP/ikea_mepnet_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q opencv-python pillow scipy scikit-image\n",
    "!pip install -q trimesh pyyaml tqdm\n",
    "!pip install -q wandb tensorboard\n",
    "\n",
    "# Install ChamferDistance (for GPU)\n",
    "!pip install -q chamferdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify PyTorch GPU setup\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download IKEA Dataset\n",
    "\n",
    "The IKEA Manuals at Work dataset contains furniture assembly instructions with 3D models and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset (this will take several minutes)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path('./IKEA-Manuals-at-Work')\n",
    "\n",
    "if not dataset_dir.exists():\n",
    "    print(\"Downloading IKEA dataset...\")\n",
    "    \n",
    "    # Download from official source\n",
    "    # Note: Update this URL with the actual dataset download link\n",
    "    !wget -O ikea_dataset.zip \"https://ikeamanuals.github.io/dataset/IKEA_Manuals_at_Work.zip\"\n",
    "    \n",
    "    print(\"Extracting dataset...\")\n",
    "    !unzip -q ikea_dataset.zip\n",
    "    !rm ikea_dataset.zip\n",
    "    \n",
    "    print(\"Dataset downloaded successfully!\")\n",
    "else:\n",
    "    print(\"Dataset already exists.\")\n",
    "\n",
    "# Check dataset structure\n",
    "!ls -lh IKEA-Manuals-at-Work/ | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Use Google Drive\n",
    "\n",
    "If direct download doesn't work, you can upload the dataset to Google Drive and mount it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if using Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # Copy dataset from Drive (if you've uploaded it there)\n",
    "# !cp -r /content/drive/MyDrive/IKEA-Manuals-at-Work ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GPU training configuration\n",
    "config_content = \"\"\"# IKEA MEPNet Training Configuration for Colab GPU\n",
    "\n",
    "# Experiment settings\n",
    "exp_name: \"ikea_mepnet_colab\"\n",
    "exp_dir: \"./experiments/ikea_mepnet_colab\"\n",
    "use_wandb: true  # Enable for experiment tracking\n",
    "wandb_project: \"ikea-mepnet\"\n",
    "use_tensorboard: true\n",
    "\n",
    "# Model configuration\n",
    "model:\n",
    "  # Architecture\n",
    "  num_stacks: 2\n",
    "  num_blocks: 1\n",
    "  num_features: 256\n",
    "  image_size: [512, 512]\n",
    "\n",
    "  # Shape conditioning\n",
    "  use_shape_condition: true\n",
    "  shape_encoding_dim: 512\n",
    "  shape_encoder_type: \"pointnet\"\n",
    "\n",
    "  # Output heads\n",
    "  num_keypoints: 16\n",
    "  num_rotation_bins: 24\n",
    "  use_continuous_rotation: true\n",
    "  max_parts: 10\n",
    "  detect_parts: true\n",
    "  predict_mask: true\n",
    "  predict_depth: false\n",
    "\n",
    "  # Training\n",
    "  intermediate_supervision: true\n",
    "\n",
    "# Data configuration\n",
    "data:\n",
    "  root_dir: \"./IKEA-Manuals-at-Work\"\n",
    "\n",
    "  dataset_args:\n",
    "    load_meshes: true  # Enable for full training\n",
    "    load_videos: false\n",
    "    furniture_categories: null  # null = all categories\n",
    "    max_parts_per_step: 10\n",
    "    image_size: [512, 512]\n",
    "    normalize_scale: true\n",
    "    cache_meshes: true\n",
    "\n",
    "  augmentation:\n",
    "    # Basic augmentations\n",
    "    use_crop: true\n",
    "    crop_size: [480, 480]\n",
    "    preserve_center: true\n",
    "    use_scale: true\n",
    "    scale_range: [0.9, 1.1]\n",
    "    use_color_jitter: true\n",
    "    brightness: 0.2\n",
    "    contrast: 0.2\n",
    "    saturation: 0.2\n",
    "    hue: 0.1\n",
    "\n",
    "    # Manual-specific augmentations\n",
    "    use_manual_style: true\n",
    "    sketch_prob: 0.3\n",
    "    edge_prob: 0.2\n",
    "    binarize_prob: 0.1\n",
    "\n",
    "    # Pose augmentation\n",
    "    use_pose_noise: true\n",
    "    rot_noise_deg: 3.0\n",
    "    trans_noise_ratio: 0.03\n",
    "\n",
    "    # Normalization\n",
    "    normalize: true\n",
    "\n",
    "# Loss configuration\n",
    "loss:\n",
    "  keypoint_weight: 1.0\n",
    "  rotation_weight: 1.0\n",
    "  translation_weight: 1.0\n",
    "  mask_weight: 0.5\n",
    "  part_detection_weight: 0.5\n",
    "  depth_weight: 0.3\n",
    "  use_continuous_rotation: true\n",
    "  intermediate_supervision: true\n",
    "\n",
    "# Optimization configuration\n",
    "optimization:\n",
    "  optimizer: \"adamw\"\n",
    "  lr: 0.0001\n",
    "  weight_decay: 0.01\n",
    "  scheduler: \"cosine\"\n",
    "  min_lr: 0.000001\n",
    "\n",
    "# Training configuration\n",
    "batch_size: 8  # Adjust based on GPU memory\n",
    "val_batch_size: 8\n",
    "epochs: 100  # Full training\n",
    "num_workers: 2\n",
    "device: \"cuda\"\n",
    "use_multi_gpu: false\n",
    "gradient_clip: 1.0\n",
    "\n",
    "# Validation and saving\n",
    "val_frequency: 1\n",
    "save_frequency: 10\n",
    "\n",
    "# Evaluation metrics\n",
    "metrics:\n",
    "  - \"pose_accuracy\"\n",
    "  - \"chamfer_distance\"\n",
    "  - \"mask_iou\"\n",
    "  - \"plan_accuracy\"\n",
    "  - \"assembly_feasibility\"\n",
    "\n",
    "# Evaluation settings\n",
    "save_predictions: true\n",
    "\"\"\"\n",
    "\n",
    "with open('configs/train_config_colab.yaml', 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"Configuration saved to configs/train_config_colab.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Login to Weights & Biases (Optional)\n",
    "\n",
    "W&B provides experiment tracking, visualization, and model versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to W&B (get API key from https://wandb.ai/authorize)\n",
    "import wandb\n",
    "\n",
    "# Option 1: Interactive login\n",
    "wandb.login()\n",
    "\n",
    "# Option 2: Use API key directly\n",
    "# wandb.login(key=\"YOUR_API_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "!python scripts/train/train_ikea.py --config configs/train_config_colab.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monitor Training\n",
    "\n",
    "Training progress can be monitored through:\n",
    "- **W&B Dashboard**: Check your wandb project page\n",
    "- **TensorBoard**: Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir experiments/ikea_mepnet_colab/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resume Training (if interrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find latest checkpoint\n",
    "!ls -lht experiments/ikea_mepnet_colab/checkpoints/ | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume from checkpoint\n",
    "!python scripts/train/train_ikea.py \\\n",
    "    --config configs/train_config_colab.yaml \\\n",
    "    --resume experiments/ikea_mepnet_colab/checkpoints/checkpoint_latest.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "!python eval/eval_ikea.py \\\n",
    "    --config configs/train_config_colab.yaml \\\n",
    "    --checkpoint experiments/ikea_mepnet_colab/checkpoints/checkpoint_best.pth \\\n",
    "    --output_dir experiments/ikea_mepnet_colab/evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load evaluation results\n",
    "results_dir = Path('experiments/ikea_mepnet_colab/evaluation')\n",
    "\n",
    "if results_dir.exists():\n",
    "    # Show some prediction visualizations\n",
    "    viz_dir = results_dir / 'visualizations'\n",
    "    if viz_dir.exists():\n",
    "        images = list(viz_dir.glob('*.png'))[:6]\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, img_path in enumerate(images):\n",
    "            img = Image.open(img_path)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(img_path.stem)\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Show metrics\n",
    "    metrics_file = results_dir / 'metrics.json'\n",
    "    if metrics_file.exists():\n",
    "        with open(metrics_file) as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        print(\"\\n=== Evaluation Metrics ===\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "else:\n",
    "    print(\"No evaluation results found. Run evaluation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the experiment folder for download\n",
    "!zip -r ikea_mepnet_trained.zip experiments/ikea_mepnet_colab/\n",
    "\n",
    "# Download to local machine\n",
    "from google.colab import files\n",
    "files.download('ikea_mepnet_trained.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save to Google Drive (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy results to Google Drive for safe keeping\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!cp -r experiments/ikea_mepnet_colab /content/drive/MyDrive/\n",
    "print(\"Results saved to Google Drive!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
